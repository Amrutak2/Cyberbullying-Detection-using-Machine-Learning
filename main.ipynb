{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Text Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>If there's one good thing about what OG are do...</td>\n",
       "      <td>Non-Bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Fucking cunt meet me in Asda.</td>\n",
       "      <td>Bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>It is widely acknowledged that Erdogan is a go...</td>\n",
       "      <td>Non-Bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>I think all cishet men should have to take a c...</td>\n",
       "      <td>Bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Could you do your videos with less feminism an...</td>\n",
       "      <td>Bullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet    Text Label\n",
       "388  If there's one good thing about what OG are do...  Non-Bullying\n",
       "972                      Fucking cunt meet me in Asda.      Bullying\n",
       "273  It is widely acknowledged that Erdogan is a go...  Non-Bullying\n",
       "872  I think all cishet men should have to take a c...      Bullying\n",
       "763  Could you do your videos with less feminism an...      Bullying"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "# Shuffle data to get randomized sequence of observations.\n",
    "df = df.sample(frac=1, random_state=1500)\n",
    "\n",
    "# Print first 5 rows of the data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is  (1065, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print shape of dataset.\n",
    "print('Dataset shape is ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Ratio of observations'}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Text Label'].value_counts(normalize=True).plot(kind='bar', title='Ratio of observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Text Label</th>\n",
       "      <th>Processed_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>If there's one good thing about what OG are do...</td>\n",
       "      <td>Non-Bullying</td>\n",
       "      <td>there one good thing og theyre bringing eu mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Fucking cunt meet me in Asda.</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>fucking cunt meet asda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>It is widely acknowledged that Erdogan is a go...</td>\n",
       "      <td>Non-Bullying</td>\n",
       "      <td>widely acknowledged erdogan goatfucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>I think all cishet men should have to take a c...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>think cishet men take class called shut fuck s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Could you do your videos with less feminism an...</td>\n",
       "      <td>Bullying</td>\n",
       "      <td>could video le feminism postmodernism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet    Text Label  \\\n",
       "388  If there's one good thing about what OG are do...  Non-Bullying   \n",
       "972                      Fucking cunt meet me in Asda.      Bullying   \n",
       "273  It is widely acknowledged that Erdogan is a go...  Non-Bullying   \n",
       "872  I think all cishet men should have to take a c...      Bullying   \n",
       "763  Could you do your videos with less feminism an...      Bullying   \n",
       "\n",
       "                                       Processed_Tweet  \n",
       "388  there one good thing og theyre bringing eu mas...  \n",
       "972                             fucking cunt meet asda  \n",
       "273             widely acknowledged erdogan goatfucker  \n",
       "872  think cishet men take class called shut fuck s...  \n",
       "763              could video le feminism postmodernism  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    # Remove words other than alphabets.\n",
    "    row = re.sub(\"[^A-Za-z ]\", \"\", tweet).lower()\n",
    "    \n",
    "    # Tokenize words.\n",
    "    words = word_tokenize(row)\n",
    "\n",
    "    # Remove stop words.\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove un-necessary words.\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
    "    clean_words = [word for word in words if word not in english_stops and word not in characters_to_remove]\n",
    "\n",
    "    # Lematise words.\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "\n",
    "    return \" \".join(lemma_list)\n",
    "\n",
    "df['Processed_Tweet'] = df['Tweet'].map(preprocess_tweet)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words.\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(df['Processed_Tweet']).toarray()\n",
    "\n",
    "# Label encode.\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['Text Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 lables in trainig set are: [0 0 1 1 1]\n",
      "First 5 lables in test set are: [1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Split dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print('First 5 lables in trainig set are:', y_train[0:5])\n",
    "print('First 5 lables in test set are:', y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows of training set is  798\n",
      "No. of rows of testing set is  267\n"
     ]
    }
   ],
   "source": [
    "print('No. of rows of training set is ', X_train.shape[0])\n",
    "print('No. of rows of testing set is ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression train set result:\n",
      "Accuracy 93.0\n",
      "Re-call 0.96\n",
      "Precision 0.92\n",
      "\n",
      "Logistic regression test set result:\n",
      "Accuracy 81.0\n",
      "Re-call 0.88\n",
      "Precision 0.81\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression.\n",
    "linear_regression_classifer = LogisticRegression(random_state=0)\n",
    "\n",
    "# Train classifier.\n",
    "linear_regression_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = linear_regression_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = linear_regression_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Logistic regression train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Logistic regression test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM train set result:\n",
      "Accuracy 92.0\n",
      "Re-call 0.97\n",
      "Precision 0.91\n",
      "\n",
      "SVM test set result:\n",
      "Accuracy 76.0\n",
      "Re-call 0.9\n",
      "Precision 0.74\n"
     ]
    }
   ],
   "source": [
    "# SVM Regression.\n",
    "svm_ovo_classifer = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Train classifier.\n",
    "svm_ovo_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = svm_ovo_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = svm_ovo_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('SVM train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('SVM test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes train set result:\n",
      "Accuracy 87.0\n",
      "Re-call 0.79\n",
      "Precision 1.0\n",
      "\n",
      "Naive bayes test set result:\n",
      "Accuracy 56.99999999999999\n",
      "Re-call 0.6\n",
      "Precision 0.64\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes Regression.\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Train classifier.\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = naive_bayes_classifier.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Naive bayes train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Naive bayes test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train set result:\n",
      "Accuracy 99.0\n",
      "Re-call 0.99\n",
      "Precision 1.0\n",
      "\n",
      "Decision tree test set result:\n",
      "Accuracy 73.0\n",
      "Re-call 0.69\n",
      "Precision 0.81\n"
     ]
    }
   ],
   "source": [
    "# Decision tree Regression.\n",
    "decision_tree_regression_classifer = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Train classifier.\n",
    "decision_tree_regression_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = decision_tree_regression_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = decision_tree_regression_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Decision tree train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Decision tree test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for training classifier using Random Forest are:  {'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# Grid search CV to find best parameters for Random Forest.\n",
    "# random_forest_params_grid = {\n",
    "#     'n_estimators': list(range(5, 50, 5)),\n",
    "#     'min_samples_leaf': list(range(1, 7)),\n",
    "#     'min_samples_split': list(range(1, 7))\n",
    "# }\n",
    "\n",
    "random_forest_params_grid = {\n",
    "    'n_estimators': list(range(5, 50, 5)),\n",
    "    'min_samples_leaf': list(range(1, 7)),\n",
    "    'min_samples_split': list(range(1, 7))\n",
    "}\n",
    "\n",
    "random_forest_grid_search_cv = GridSearchCV(RandomForestClassifier(), \n",
    "                                            random_forest_params_grid,\n",
    "                                            refit=True, scoring='accuracy',\n",
    "                                            n_jobs=-1, cv=5)\n",
    "\n",
    "\n",
    "# Train classifier.\n",
    "random_forest_grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Best params for training classifier using Random Forest are: ', \n",
    "      random_forest_grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest train set result:\n",
      "Accuracy 85.0\n",
      "Re-call 0.92\n",
      "Precision 0.85\n",
      "\n",
      "Random Forest test set result:\n",
      "Accuracy 78.0\n",
      "Re-call 0.87\n",
      "Precision 0.78\n"
     ]
    }
   ],
   "source": [
    "# Random Forest using optimal params.\n",
    "random_forest_cv = RandomForestClassifier(**random_forest_grid_search_cv.best_params_)\n",
    "\n",
    "# Train classifier.\n",
    "random_forest_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = random_forest_cv.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = random_forest_cv.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Random Forest train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Random Forest test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for training classifier using Gradient Boosting are:  {'learning_rate': 0.2, 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 17}\n"
     ]
    }
   ],
   "source": [
    "# Grid search CV to find best parameters for Random Forest.\n",
    "# gradient_boosting_params_grid = {\n",
    "#     'min_samples_split': list(range(5, 10)),\n",
    "#     'min_samples_leaf': list(range(5, 10)),\n",
    "#     'n_estimators': list(range(5, 20, 3)),\n",
    "#     \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "# }\n",
    "\n",
    "gradient_boosting_params_grid = {\n",
    "    'min_samples_split': list(range(5, 10)),\n",
    "    'min_samples_leaf': list(range(5, 10)),\n",
    "    'n_estimators': list(range(5, 20, 3)),\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "gradient_boosting_grid_search_cv = GridSearchCV(GradientBoostingClassifier(), \n",
    "                                                gradient_boosting_params_grid,\n",
    "                                                scoring='accuracy', cv=5)\n",
    "\n",
    "# Train classifier.\n",
    "gradient_boosting_grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Best params for training classifier using Gradient Boosting are: ', \n",
    "      gradient_boosting_grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier train set result:\n",
      "Accuracy 72.0\n",
      "Re-call 0.93\n",
      "Precision 0.71\n",
      "\n",
      "Gradient Boosting Classifier test set result:\n",
      "Accuracy 75.0\n",
      "Re-call 0.9\n",
      "Precision 0.73\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting classifier.\n",
    "gradient_boosting_classifier = GradientBoostingClassifier(**gradient_boosting_grid_search_cv.best_params_)\n",
    "\n",
    "# Train classifier.\n",
    "gradient_boosting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = gradient_boosting_classifier.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = gradient_boosting_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Gradient Boosting Classifier train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Gradient Boosting Classifier test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
