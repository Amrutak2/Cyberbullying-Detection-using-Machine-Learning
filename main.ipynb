{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.sample of                                                   Tweet    Text Label\n",
       "0     .omg why are poc wearing fugly blue contacts s...  Non-Bullying\n",
       "1     .Sorry but most of the runners popular right n...  Non-Bullying\n",
       "2     .those jeans are hideous, and I?m afraid he?s ...  Non-Bullying\n",
       "3     .I had to dress up for a presentation in class...  Non-Bullying\n",
       "4     .Am I the only one who thinks justin bieber is...  Non-Bullying\n",
       "...                                                 ...           ...\n",
       "1060  No we are not, But you are a race baiting libt...      Bullying\n",
       "1061  you wont get anyone for this challenge., after...      Bullying\n",
       "1062  I will follow you if you are not a libtard,Mus...      Bullying\n",
       "1063  michaelianblack Ur a child, an ostrich w/ your...      Bullying\n",
       "1064  FoxNews. not to all the ppl I know that live t...      Bullying\n",
       "\n",
       "[1065 rows x 2 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "# Print first 5 rows of the data.\n",
    "df.head()\n",
    "df.sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is  (1065, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print shape of dataset.\n",
    "print('Dataset shape is ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.sample of                                                   Tweet    Text Label  \\\n",
       "0     .omg why are poc wearing fugly blue contacts s...  Non-Bullying   \n",
       "1     .Sorry but most of the runners popular right n...  Non-Bullying   \n",
       "2     .those jeans are hideous, and I?m afraid he?s ...  Non-Bullying   \n",
       "3     .I had to dress up for a presentation in class...  Non-Bullying   \n",
       "4     .Am I the only one who thinks justin bieber is...  Non-Bullying   \n",
       "...                                                 ...           ...   \n",
       "1060  No we are not, But you are a race baiting libt...      Bullying   \n",
       "1061  you wont get anyone for this challenge., after...      Bullying   \n",
       "1062  I will follow you if you are not a libtard,Mus...      Bullying   \n",
       "1063  michaelianblack Ur a child, an ostrich w/ your...      Bullying   \n",
       "1064  FoxNews. not to all the ppl I know that live t...      Bullying   \n",
       "\n",
       "                                        Processed_Tweet  \n",
       "0     omg poc wearing fugly blue contact please make...  \n",
       "1                sorry runner popular right plain fugly  \n",
       "2     jean hideous im afraid he bought entire collec...  \n",
       "3     dress presentation class today im giving serio...  \n",
       "4                      one think justin bieber fugly af  \n",
       "...                                                 ...  \n",
       "1060                     race baiting libtard jackwagon  \n",
       "1061  wont get anyone challenge snowflake libtard to...  \n",
       "1062           follow libtardmuslim ate involved blm er  \n",
       "1063  michaelianblack ur child ostrich w head sand p...  \n",
       "1064  foxnews ppl know live love libtardi suspect tr...  \n",
       "\n",
       "[1065 rows x 3 columns]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    # Remove words other than alphabets.\n",
    "    row = re.sub(\"[^A-Za-z ]\", \"\", tweet).lower()\n",
    "    \n",
    "    # Tokenize words.\n",
    "    words = word_tokenize(row)\n",
    "\n",
    "    # Remove stop words.\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove un-necessary words.\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
    "    clean_words = [word for word in words if word not in english_stops and word not in characters_to_remove]\n",
    "\n",
    "    # Lematise words.\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "\n",
    "    return \" \".join(lemma_list)\n",
    "\n",
    "df['Processed_Tweet'] = df['Tweet'].map(preprocess_tweet)\n",
    "\n",
    "df.head()\n",
    "df.sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of word\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(df['Processed_Tweet']).toarray()\n",
    "\n",
    "# Label encode\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['Text Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Y Train [1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Split dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print('X Train', X_train[0:5])\n",
    "print('Y Train', y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows of training set is  798\n",
      "No. of rows of training set is  267\n"
     ]
    }
   ],
   "source": [
    "print('No. of rows of training set is ', X_train.shape[0])\n",
    "print('No. of rows of training set is ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression train set result:\n",
      "Accuracy 93.0\n",
      "Re-call 0.97\n",
      "Precision 0.92\n",
      "\n",
      "Logistic regression test set result:\n",
      "Accuracy 73.0\n",
      "Re-call 0.81\n",
      "Precision 0.77\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression.\n",
    "linear_regression_classifer = LogisticRegression(random_state=0)\n",
    "\n",
    "# Train classifier.\n",
    "linear_regression_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = linear_regression_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = linear_regression_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Logistic regression train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Logistic regression test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM train set result:\n",
      "Accuracy 93.0\n",
      "Re-call 0.97\n",
      "Precision 0.92\n",
      "\n",
      "SVM test set result:\n",
      "Accuracy 74.0\n",
      "Re-call 0.9\n",
      "Precision 0.75\n"
     ]
    }
   ],
   "source": [
    "# SVM Regression.\n",
    "svm_ovo_classifer = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Train classifier.\n",
    "svm_ovo_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = svm_ovo_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = svm_ovo_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('SVM train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('SVM test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes train set result:\n",
      "Accuracy 86.0\n",
      "Re-call 0.76\n",
      "Precision 1.0\n",
      "\n",
      "Naive bayes test set result:\n",
      "Accuracy 59.0\n",
      "Re-call 0.53\n",
      "Precision 0.75\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes Regression.\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Train classifier.\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = naive_bayes_classifier.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Naive bayes train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Naive bayes test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train set result:\n",
      "Accuracy 99.0\n",
      "Re-call 1.0\n",
      "Precision 0.99\n",
      "\n",
      "Decision tree test set result:\n",
      "Accuracy 72.0\n",
      "Re-call 0.7\n",
      "Precision 0.83\n"
     ]
    }
   ],
   "source": [
    "# Decision tree Regression.\n",
    "decision_tree_regression_classifer = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Train classifier.\n",
    "decision_tree_regression_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = decision_tree_regression_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = decision_tree_regression_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Decision tree train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Decision tree test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier train set result:\n",
      "Accuracy 59.0\n",
      "Re-call 1.0\n",
      "Precision 0.59\n",
      "\n",
      "Random Forest Classifier test set result:\n",
      "Accuracy 63.0\n",
      "Re-call 1.0\n",
      "Precision 0.63\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier.\n",
    "random_forest_classifer = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# Train classifier.\n",
    "random_forest_classifer.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = random_forest_classifer.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = random_forest_classifer.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Random Forest Classifier train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Random Forest Classifier test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier train set result:\n",
      "Accuracy 85.0\n",
      "Re-call 0.95\n",
      "Precision 0.82\n",
      "\n",
      "Gradient Boosting Classifier test set result:\n",
      "Accuracy 73.0\n",
      "Re-call 0.84\n",
      "Precision 0.76\n"
     ]
    }
   ],
   "source": [
    "#  Gradient Boosting classifier.\n",
    "Gradient_Boost_Classifier = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# Train classifier.\n",
    "Gradient_Boost_Classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = Gradient_Boost_Classifier.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = Gradient_Boost_Classifier.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Gradient Boosting Classifier train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Gradient Boosting Classifier test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search CV train set result:\n",
      "Accuracy 85.0\n",
      "Re-call 0.95\n",
      "Precision 0.82\n",
      "\n",
      "Grid Search CV test set result:\n",
      "Accuracy 73.0\n",
      "Re-call 0.85\n",
      "Precision 0.75\n"
     ]
    }
   ],
   "source": [
    "#  Grid search CV .\n",
    "parameters = {}\n",
    "\n",
    "Grid_Search_CV = GridSearchCV(GradientBoostingClassifier(), parameters)\n",
    "\n",
    "# Train classifier.\n",
    "Grid_Search_CV.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set.\n",
    "y_train_pred = Grid_Search_CV.predict(X_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_test_pred = Grid_Search_CV.predict(X_test)\n",
    "\n",
    "# Accuracy and other metrics.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='binary')\n",
    "train_precision = precision_score(y_train, y_train_pred, average='binary')\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='binary')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "print('Grid Search CV train set result:')\n",
    "print('Accuracy', round(train_accuracy, 2) * 100)\n",
    "print('Re-call', round(train_recall, 2))\n",
    "print('Precision', round(train_precision, 2))\n",
    "print()\n",
    "print('Grid Search CV test set result:')\n",
    "print('Accuracy', round(test_accuracy, 2) * 100)\n",
    "print('Re-call', round(test_recall, 2))\n",
    "print('Precision', round(test_precision, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
